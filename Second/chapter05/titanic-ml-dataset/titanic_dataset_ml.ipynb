{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "8589efef-b5b3-493c-9ed9-c5e9150f8d1b",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "## Machine Learning on Titanic passengers survival data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "cff97bb6-cca5-479d-a5e3-7796cc225b68",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "This Notebook will use machine learning to create a model that predicts which passengers survived the Titanic shipwreck. The dataset provides information on the fate of passengers on the Titanic, summarized according to economic status (class), sex, age and survival.\n",
    "\n",
    "Credit for this Notebook goes to Niklas Donges, who published a very detailed post [here](https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8). Check it out if you want to dive deeper in the data analysis and machine learning details of the challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "6992d783-0fc0-4969-b64c-10bc30f2682a",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "#### Import dependencies and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "cd9dada5-6819-4dd2-9ce4-4b891d9dc95c",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (3.7.1)\n",
      "Requirement already satisfied: numpy==1.25.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.25.0)\n",
      "Collecting pandas==1.5.3\n",
      "  Using cached pandas-1.5.3-cp39-cp39-macosx_10_9_x86_64.whl (12.0 MB)\n",
      "Collecting scikit-learn==1.2.2\n",
      "  Using cached scikit_learn-1.2.2-cp39-cp39-macosx_10_9_x86_64.whl (9.1 MB)\n",
      "Collecting seaborn==0.12.2\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Collecting mlflow<2.0.0\n",
      "  Using cached mlflow-1.30.1-py3-none-any.whl (17.0 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from pandas==1.5.3->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from pandas==1.5.3->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 4)) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (10.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (5.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (4.40.0)\n",
      "Collecting Flask<3\n",
      "  Using cached Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "Collecting entrypoints<1\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<6,>=3.7.0\n",
      "  Using cached importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from mlflow<2.0.0->-r requirements.txt (line 6)) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle<3 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from mlflow<2.0.0->-r requirements.txt (line 6)) (2.2.1)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from mlflow<2.0.0->-r requirements.txt (line 6)) (3.1.31)\n",
      "Collecting gunicorn<21\n",
      "  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: alembic<2 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from mlflow<2.0.0->-r requirements.txt (line 6)) (1.11.1)\n",
      "Collecting querystring-parser<2\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting prometheus-flask-exporter<1\n",
      "  Using cached prometheus_flask_exporter-0.22.4-py3-none-any.whl (18 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Using cached databricks_cli-0.17.7-py3-none-any.whl\n",
      "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from mlflow<2.0.0->-r requirements.txt (line 6)) (1.4.48)\n",
      "Collecting docker<7,>=4.0.0\n",
      "  Using cached docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from mlflow<2.0.0->-r requirements.txt (line 6)) (6.0)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from mlflow<2.0.0->-r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from mlflow<2.0.0->-r requirements.txt (line 6)) (3.20.3)\n",
      "Requirement already satisfied: Mako in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from alembic<2->mlflow<2.0.0->-r requirements.txt (line 6)) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from alembic<2->mlflow<2.0.0->-r requirements.txt (line 6)) (4.7.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow<2.0.0->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow<2.0.0->-r requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.7 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow<2.0.0->-r requirements.txt (line 6)) (1.26.16)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Using cached PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow<2.0.0->-r requirements.txt (line 6)) (3.2.2)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from docker<7,>=4.0.0->mlflow<2.0.0->-r requirements.txt (line 6)) (1.6.1)\n",
      "Collecting Werkzeug>=2.3.3\n",
      "  Using cached Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from Flask<3->mlflow<2.0.0->-r requirements.txt (line 6)) (3.1.2)\n",
      "Collecting blinker>=1.6.2\n",
      "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting itsdangerous>=2.1.2\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from gitpython<4,>=2.1.0->mlflow<2.0.0->-r requirements.txt (line 6)) (4.0.10)\n",
      "Requirement already satisfied: setuptools>=3.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from gunicorn<21->mlflow<2.0.0->-r requirements.txt (line 6)) (58.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow<2.0.0->-r requirements.txt (line 6)) (3.15.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from prometheus-flask-exporter<1->mlflow<2.0.0->-r requirements.txt (line 6)) (0.17.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow<2.0.0->-r requirements.txt (line 6)) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow<2.0.0->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow<2.0.0->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from sqlalchemy<2,>=1.4.0->mlflow<2.0.0->-r requirements.txt (line 6)) (2.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow<2.0.0->-r requirements.txt (line 6)) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages (from Jinja2>=3.1.2->Flask<3->mlflow<2.0.0->-r requirements.txt (line 6)) (2.1.3)\n",
      "Installing collected packages: pytz, Werkzeug, sqlparse, querystring-parser, pyjwt, packaging, itsdangerous, importlib-metadata, gunicorn, entrypoints, blinker, scikit-learn, pandas, Flask, docker, databricks-cli, seaborn, prometheus-flask-exporter, mlflow\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2023.3\n",
      "    Uninstalling pytz-2023.3:\n",
      "      Successfully uninstalled pytz-2023.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.7.0\n",
      "    Uninstalling importlib-metadata-6.7.0:\n",
      "      Successfully uninstalled importlib-metadata-6.7.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "Successfully installed Flask-2.3.2 Werkzeug-2.3.6 blinker-1.6.2 databricks-cli-0.17.7 docker-6.1.3 entrypoints-0.4 gunicorn-20.1.0 importlib-metadata-5.2.0 itsdangerous-2.1.2 mlflow-1.30.1 packaging-21.3 pandas-1.5.3 prometheus-flask-exporter-0.22.4 pyjwt-2.7.0 pytz-2022.7.1 querystring-parser-1.2.4 scikit-learn-1.2.2 seaborn-0.12.2 sqlparse-0.4.4\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "0e5298b8-0ff0-45a1-84ee-a6f885db8c3c",
     "isComponent": true,
     "name": "import",
     "parents": []
    },
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "147b897c-09bc-46d4-8a5a-969855bf3877",
     "isComponent": true,
     "name": "read file",
     "parents": [
      {
       "id": "0e5298b8-0ff0-45a1-84ee-a6f885db8c3c",
       "name": "import"
      }
     ]
    },
    "tags": [
     "block:loaddata"
    ]
   },
   "outputs": [],
   "source": [
    "PREDICTION_LABEL = 'Survived'\n",
    "train_df = pd.read_csv(\"https://raw.githubusercontent.com/kubeflow-kale/kale/master/examples/titanic-ml-dataset/data/train.csv\")\n",
    "test_df = pd.read_csv(\"https://raw.githubusercontent.com/kubeflow-kale/kale/master/examples/titanic-ml-dataset/data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "15ba507d-3ec6-45c0-a9a9-8bbf4654fa33",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "#### Let's explore the data\n",
    "\n",
    "These are features of the dataset:\n",
    "```\n",
    "survival:    Survival \n",
    "PassengerId: Unique Id of a passenger. \n",
    "pclass:    Ticket class     \n",
    "sex:    Sex     \n",
    "Age:    Age in years     \n",
    "sibsp:    # of siblings / spouses aboard the Titanic     \n",
    "parch:    # of parents / children aboard the Titanic     \n",
    "ticket:    Ticket number     \n",
    "fare:    Passenger fare     \n",
    "cabin:    Cabin number     \n",
    "embarked:    Port of Embarkation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "9724314e-8e60-4044-a195-4e299b53f062",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "6036bc52-dc61-43bd-93f7-b54d56648c67",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "5477376e-4e7a-41ad-af6b-3feb03159233",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "train_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "5748cc40-d825-4280-8948-73e129a55c3d",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "**Missing data**\n",
    "\n",
    "Let's see here how much data is missing. We will have to fill the missing features later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "33d8fb72-def9-47cc-a354-32cc9794c3c3",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "35fa89e9-bb1e-4ea5-bc26-ee5eddad063e",
     "isComponent": true,
     "name": "data processing",
     "parents": [
      {
       "id": "147b897c-09bc-46d4-8a5a-969855bf3877",
       "name": "read file"
      }
     ]
    },
    "tags": [
     "block:datapreprocessing",
     "prev:loaddata"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>relatives</th>\n",
       "      <th>not_alone</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Fare_Per_Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  relatives  \\\n",
       "0         0       3    0    2      1      0     0         0          1   \n",
       "1         1       1    1    5      1      0     3         1          1   \n",
       "2         1       3    1    3      0      0     0         0          0   \n",
       "3         1       1    1    5      1      0     3         0          1   \n",
       "4         0       3    0    5      0      0     1         0          0   \n",
       "5         0       3    0    2      0      0     1         2          0   \n",
       "6         0       1    0    6      0      0     3         0          0   \n",
       "7         0       3    0    0      3      1     2         0          4   \n",
       "8         1       3    1    3      0      2     1         0          2   \n",
       "9         1       2    1    1      1      0     2         1          1   \n",
       "\n",
       "   not_alone  Deck  Title  Age_Class  Fare_Per_Person  \n",
       "0          0     8      1          6                0  \n",
       "1          0     3      3          5                1  \n",
       "2          1     8      2          9                0  \n",
       "3          0     3      3          5                1  \n",
       "4          1     8      1         15                1  \n",
       "5          1     8      1          6                1  \n",
       "6          1     5      1          6                3  \n",
       "7          0     8      4          0                0  \n",
       "8          0     8      3          9                0  \n",
       "9          0     8      3          2                1  "
      ]
     },
     "execution_count": 0,
     "metadata": {
      "component_id": "35fa89e9-bb1e-4ea5-bc26-ee5eddad063e"
     },
     "output_type": "execute_result"
    },
    {
     "data": {},
     "execution_count": 0,
     "metadata": {
      "component_id": "35fa89e9-bb1e-4ea5-bc26-ee5eddad063e"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = train_df.isnull().sum()/train_df.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "missing_data.head(5)\n",
    "\n",
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n",
    "    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n",
    "    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n",
    "    dataset['not_alone'] = dataset['not_alone'].astype(int)\n",
    "train_df['not_alone'].value_counts()\n",
    "\n",
    "# This does not contribute to a person survival probability\n",
    "train_df = train_df.drop(['PassengerId'], axis=1)\n",
    "\n",
    "import re\n",
    "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
    "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
    "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
    "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
    "# we can now drop the cabin feature\n",
    "train_df = train_df.drop(['Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Cabin'], axis=1)\n",
    "\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    mean = train_df[\"Age\"].mean()\n",
    "    std = test_df[\"Age\"].std()\n",
    "    is_null = dataset[\"Age\"].isnull().sum()\n",
    "    # compute random numbers between the mean, std and is_null\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = dataset[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"Age\"] = age_slice\n",
    "    dataset[\"Age\"] = train_df[\"Age\"].astype(int)\n",
    "train_df[\"Age\"].isnull().sum()\n",
    "\n",
    "# fill with most common value\n",
    "common_value = 'S'\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)\n",
    "    \n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "data = [train_df, test_df]\n",
    "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "\n",
    "for dataset in data:\n",
    "    # extract titles\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    # replace titles with a more common title or as Rare\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
    "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    # convert titles into numbers\n",
    "    dataset['Title'] = dataset['Title'].map(titles)\n",
    "    # filling NaN with 0, to get safe\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "train_df = train_df.drop(['Name'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "\n",
    "genders = {\"male\": 0, \"female\": 1}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(genders)\n",
    "\n",
    "\n",
    "train_df = train_df.drop(['Ticket'], axis=1)\n",
    "test_df = test_df.drop(['Ticket'], axis=1)\n",
    "\n",
    "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(ports)\n",
    "\n",
    "\n",
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
    "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n",
    "\n",
    "# let's see how it's distributed train_df['Age'].value_counts()\n",
    "\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
    "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['Age_Class']= dataset['Age']* dataset['Pclass']\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Fare_Per_Person'] = dataset['Fare']/(dataset['relatives']+1)\n",
    "    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)\n",
    "# Let's take a last look at the training set, before we start training the models.\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "65bf8315-d50c-468f-beb6-9c096393d1c3",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## ML\n",
    "\n",
    "Because the dataset does not provide labels for their testing-set, we need to use the predictions on the training set to compare the algorithms with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "7cda5af8-9d48-4658-9e8d-0b0a3a9c926a",
     "isComponent": true,
     "name": "fit",
     "parents": [
      {
       "id": "35fa89e9-bb1e-4ea5-bc26-ee5eddad063e",
       "name": "data processing"
      }
     ]
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/02 01:58:32 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2023/07/02 01:58:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/jyc/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "kubeflow_run_id = os.getenv(\"KUBEFLOW_RUN_ID\", None)\n",
    "if kubeflow_run_id is None:\n",
    "    # Local jupyter\n",
    "    mlflow.set_tracking_uri(\"http://localhost:59000\")\n",
    "else:\n",
    "    # Running on kubeflow pipeline\n",
    "    mlflow.set_tracking_uri(\"http://mlflow-server-service.mlflow-system:5000\")\n",
    "\n",
    "train_labels = train_df[PREDICTION_LABEL]\n",
    "train_df = train_df.drop(PREDICTION_LABEL, axis=1)\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run() as run:\n",
    "    random_forest.fit(train_df, train_labels)\n",
    "    acc_random_forest = round(random_forest.score(train_df, train_labels) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "a131c857-0984-4fdc-9b72-602d64020a77",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "1b3a5392-2759-45dd-a430-42e601d313ae",
     "isComponent": true,
     "name": "result",
     "parents": [
      {
       "id": "7cda5af8-9d48-4658-9e8d-0b0a3a9c926a",
       "name": "fit"
      }
     ]
    },
    "tags": [
     "block:results",
     "prev:randomforest",
     "prev:logisticregression",
     "prev:naivebayes",
     "prev:svm",
     "prev:decisiontree"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model\n",
      "Score               \n",
      "92.93  Random Forest\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Random Forest'],\n",
    "    'Score': [acc_random_forest,]\n",
    "})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "fc682408-4332-40f9-98f6-472c56f20f63",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "65869663-7ada-4e44-a634-284ece5cc548",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "0c002beb-86e1-4e9e-8bb7-6f00a186b651",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "",
   "experiment_name": "titanic",
   "pipeline_description": "Predict which passengers survived the Titanic shipwreck",
   "pipeline_name": "titanic-ml",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
